{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5c539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "street_signs = pd.read_csv('MergedData/intersections_collision_streetlights_streets_street_sign.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2283604c",
   "metadata": {},
   "source": [
    "## functions for linear regression and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import shap\n",
    "\n",
    "def linear_regression(data, Y_name):\n",
    "\n",
    "    X = data.drop(Y_name, axis=1)\n",
    "    y = data[Y_name]\n",
    "\n",
    "    categorical_features = ['SIGNAL_TYPE']\n",
    "    numeric_features = ['COUNT_RELATED_STREETS', 'AVG_PVMT_CONDITION', 'AVG_SPEEDLIMIT', 'TRAFFIC_CIRCLE_EXISTS', 'COUNT_STOPSIGNS', 'COUNT_YEILDSIGNS', 'LIGHTPOLE_COUNT', 'LIGHTPOLE_AVG_HEIGHT']\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', 'passthrough', numeric_features),\n",
    "            ('cat', OneHotEncoder(), categorical_features)])\n",
    "    \n",
    "    X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "\n",
    "    X_preprocessed = X_preprocessed.astype(float)\n",
    "\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Fit the model with the training data\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    scores = cross_val_score(model, X_preprocessed, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    mean_score = np.mean(scores)\n",
    "    print('Mean Cross-Validated Mean Squared Error:', -mean_score)\n",
    "\n",
    "\n",
    "    X_preprocessed = sm.add_constant(X_preprocessed)\n",
    "\n",
    "\n",
    "    sm_model = sm.OLS(y, X_preprocessed)\n",
    "    results = sm_model.fit()\n",
    "\n",
    "\n",
    "    X_numeric = data[numeric_features]\n",
    "    correlations = X_numeric.corrwith(data[Y_name])\n",
    "    print('\\nFeature Correlations:')\n",
    "    print(correlations)\n",
    "\n",
    "\n",
    "    p_values = results.pvalues\n",
    "\n",
    "\n",
    "    column_names = numeric_features + preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()\n",
    "    column_names.insert(0, 'Intercept')\n",
    "\n",
    "\n",
    "    feature_p_values = dict(zip(column_names, p_values))\n",
    "\n",
    "\n",
    "    sorted_features = sorted(feature_p_values.items(), key=lambda x: x[1])\n",
    "\n",
    "\n",
    "    print('\\nSorted Features by P-values:')\n",
    "    for feature, p_value in sorted_features:\n",
    "        print(f\"{feature}: {p_value}\")\n",
    "\n",
    "    # Create a SHAP explainer object for the random forest model\n",
    "    explainer = shap.Explainer(model, X_train)\n",
    "\n",
    "    # Calculate SHAP values for the test set\n",
    "    shap_values = explainer(X_test)\n",
    "\n",
    "    # Generate the summary plot\n",
    "    shap.summary_plot(shap_values, X_test, feature_names=column_names[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e43b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import shap\n",
    "\n",
    "def random_forest(data,Y_name):\n",
    "   # Split the dataset into input features X and target variable y\n",
    "    X = data.drop(columns=[Y_name])\n",
    "    y = data[Y_name]\n",
    "\n",
    "    # Convert boolean values to integers (0 and 1)\n",
    "    X['TRAFFIC_CIRCLE_EXISTS'] = X['TRAFFIC_CIRCLE_EXISTS'].astype(int)\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    categorical_columns = ['SIGNAL_TYPE']\n",
    "    X = pd.get_dummies(X, columns=categorical_columns)\n",
    "\n",
    "    # Convert boolean columns to integer\n",
    "    bool_columns = X.select_dtypes(include='bool').columns\n",
    "    X[bool_columns] = X[bool_columns].astype(int)\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Create a random forest regressor\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Evaluate model performance using cross-validation\n",
    "    cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate mean squared error on the test set\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    print(\"Cross-validation scores:\", -cv_scores)\n",
    "    print(\"Mean squared error on test set:\", mse)\n",
    "\n",
    "    # Create a SHAP explainer object for the random forest model\n",
    "    explainer = shap.Explainer(rf, X_train)\n",
    "    \n",
    "    # Calculate SHAP values for the test set\n",
    "    shap_values = explainer(X_test,check_additivity=False)\n",
    "\n",
    "    # Generate the summary plot\n",
    "    shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286395a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_1 = street_signs[street_signs[\"related_street_num\"] == 1]\n",
    "rows_with_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25716a0d",
   "metadata": {},
   "source": [
    "## Part I street_signs modeling\n",
    "### import data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_signs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b640b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_signs[\"traffic_flow_index\"] = street_signs[\"ARTERIALCLASSCD\"] + 1\n",
    "street_signs[\"collision_rate \"] = street_signs[\"collision_count\"] / street_signs[\"traffic_flow_index\"]\n",
    "\n",
    "street_signs = street_signs.drop(columns=[\"ARTERIALCLASSCD\", \"traffic_flow_index\", \"collision_count\"])\n",
    "\n",
    "street_signs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_signs = street_signs.drop(columns=[\"X\", \"Y\", \"UNITDESC\"])\n",
    "\n",
    "street_signs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d9a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "street_signs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b62432d",
   "metadata": {},
   "source": [
    "### Use cross validation+random forest to do the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44046b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the dataset into input features X and target variable y\n",
    "X = street_signs.drop(columns=[\"collision_rate \"])\n",
    "y = street_signs[\"collision_rate \"]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Evaluate model performance using cross-validation\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Cross-validation scores:\", -cv_scores)\n",
    "print(\"Mean squared error on test set:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952e3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean of collision_rate: {street_signs['collision_rate '].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86373e2c",
   "metadata": {},
   "source": [
    "### ChatGPT interpolate the result\n",
    "##### The training results show the cross-validation scores and the mean squared error on the test set when modeling the data using a random forest regressor.\n",
    "\n",
    "##### Cross-Validation Scores:\n",
    "##### The cross-validation scores are a list containing 5 values, each representing the performance of the model on a different training/validation data split. Here, the negative mean squared error is used as the scoring metric. Generally, a lower mean squared error indicates better model performance. However, in this case, we use the negative mean squared error, so values closer to 0 indicate better performance.\n",
    "\n",
    "##### 1st cross-validation score: 0.08300897\n",
    "##### 2nd cross-validation score: 0.08858813\n",
    "##### 3rd cross-validation score: 0.08617691\n",
    "##### 4th cross-validation score: 0.08685302\n",
    "##### 5th cross-validation score: 0.08686454\n",
    "##### Test Set Mean Squared Error:\n",
    "##### The mean squared error (MSE) on the test set is a single value that represents the error the model produces when predicting unseen data. The MSE is a commonly used metric for measuring prediction accuracy. A lower value indicates better performance on the test set.\n",
    "\n",
    "##### Test set mean squared error: 0.08771023589859456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560a4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer object for the random forest model\n",
    "explainer = shap.Explainer(rf, X_train)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer(X_test,check_additivity=False)\n",
    "\n",
    "# Generate the summary plot\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59fd66d",
   "metadata": {},
   "source": [
    "## Part II traffic_signals modeling\n",
    "### import data and pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_signals = pd.read_csv('MergedData/intersections_collision_streetlights_streets_traffic_signals.csv')\n",
    "first_row = traffic_signals.iloc[1]\n",
    "for column_name, value in zip(traffic_signals.columns, first_row):\n",
    "    print(f\"{column_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a5101",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_signals[\"traffic_flow_index\"] = traffic_signals[\"ARTERIALCLASSCD\"] + 1\n",
    "traffic_signals[\"collision_rate \"] = traffic_signals[\"collision_count\"] / traffic_signals[\"traffic_flow_index\"]\n",
    "\n",
    "traffic_signals = traffic_signals.drop(columns=[\"ARTERIALCLASSCD\", \"traffic_flow_index\", \"collision_count\"])\n",
    "traffic_signals = traffic_signals.drop(columns=[\"INT_SIGNAL_TYPE_CD\"])\n",
    "traffic_signals = traffic_signals.drop(columns=[\"X\", \"Y\", \"UNITDESC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_row = traffic_signals.iloc[1]\n",
    "for column_name, value in zip(traffic_signals.columns, first_row):\n",
    "    print(f\"{column_name}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae94fe1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "traffic_signals.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1963c",
   "metadata": {},
   "source": [
    "\n",
    "### Use cross validation+random forest to do the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f673be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(traffic_signals.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f55aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = traffic_signals.drop(columns=[\"collision_rate \"])\n",
    "y = traffic_signals[\"collision_rate \"]\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.001, random_state=42)\n",
    "\n",
    "# Create a random forest regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Evaluate model performance using cross-validation\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the trained model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate mean squared error on the test set\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Cross-validation scores:\", -cv_scores)\n",
    "print(\"Mean squared error on test set:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3690b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean of collision_rate: {traffic_signals['collision_rate '].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c489c4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create a SHAP explainer object for the random forest model\n",
    "explainer = shap.Explainer(rf, X_train)\n",
    "\n",
    "# Calculate SHAP values for the test set\n",
    "shap_values = explainer(X_test,check_additivity=False)\n",
    "\n",
    "# Generate the summary plot\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82113f37",
   "metadata": {},
   "source": [
    "# Part III try Minimal data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f0cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "MVP = pd.read_csv('data/JOINED_INTERSECTIONS_WO_NULLS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767cfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d191774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP = MVP.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac95a24c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MVP.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6646e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP[\"ARTERIAL_CLASSIFICATION\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d737b85",
   "metadata": {},
   "source": [
    "## Try ARTERIAL_CLASSIFICATION as traffic flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 - Interstate Freeway\n",
    "#4 - State Highway\n",
    "#1 - Principal Arterial\n",
    "#2 - Minor Arterial\n",
    "#3 - Collector Arterial\n",
    "#0 - Not Designated (not an arterial) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a215821",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP_art = MVP\n",
    "MVP_art['ARTERIAL_CLASSIFICATION'] = MVP_art['ARTERIAL_CLASSIFICATION'].replace({\n",
    "    5: 6,\n",
    "    4: 5,\n",
    "    1: 4,\n",
    "    2: 3,\n",
    "    3: 2,\n",
    "    0: 1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38b55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP_art[\"RATE_COLLISIONS\"] = MVP_art[\"COUNT_COLLISIONS\"] / MVP_art[\"ARTERIAL_CLASSIFICATION\"]\n",
    "\n",
    "MVP_art = MVP_art.drop(columns=[\"COUNT_COLLISIONS\", \"ARTERIAL_CLASSIFICATION\"])\n",
    "MVP_art = MVP_art.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334d36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP_art.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040390e0",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ee87a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = MVP_art\n",
    "linear_regression(data,\"RATE_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87316f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MVP_art\n",
    "random_forest(data,\"RATE_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba95682",
   "metadata": {},
   "source": [
    "# Try Collision (arterial classification way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972edc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVP.info()\n",
    "MVP[\"ARTERIAL_CLASSIFICATION\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cf4fe7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MVP_all= MVP\n",
    "\n",
    "#5 - Interstate Freeway\n",
    "#4 - State Highway\n",
    "#1 - Principal Arterial\n",
    "#2 - Minor Arterial\n",
    "#3 - Collector Arterial\n",
    "\n",
    "# 假设您的数据集名为MVP_art\n",
    "subsets = MVP_all.groupby('ARTERIAL_CLASSIFICATION')\n",
    "\n",
    "# 分组后，您可以通过组名（0,1,2,3,4,5）访问每个子集\n",
    "Collector_Arterial = subsets.get_group(2)\n",
    "Minor_Arterial = subsets.get_group(3)\n",
    "Principal_Arterial = subsets.get_group(4)\n",
    "State_Highway = subsets.get_group(5)\n",
    "Interstate_Freeway = subsets.get_group(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123ff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "Collector_Arterial = Collector_Arterial.drop(columns=[\"ARTERIAL_CLASSIFICATION\",\"RATE_COLLISIONS\"])\n",
    "Collector_Arterial = Collector_Arterial.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])\n",
    "\n",
    "Minor_Arterial = Minor_Arterial.drop(columns=[\"ARTERIAL_CLASSIFICATION\",\"RATE_COLLISIONS\"])\n",
    "Minor_Arterial = Minor_Arterial.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])\n",
    "\n",
    "Principal_Arterial = Principal_Arterial.drop(columns=[\"ARTERIAL_CLASSIFICATION\",\"RATE_COLLISIONS\"])\n",
    "Principal_Arterial = Principal_Arterial.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])\n",
    "\n",
    "State_Highway = State_Highway.drop(columns=[\"ARTERIAL_CLASSIFICATION\",\"RATE_COLLISIONS\"])\n",
    "State_Highway = State_Highway.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])\n",
    "\n",
    "Interstate_Freeway = Interstate_Freeway.drop(columns=[\"ARTERIAL_CLASSIFICATION\",\"RATE_COLLISIONS\"])\n",
    "Interstate_Freeway = Interstate_Freeway.drop(columns=[\"X\", \"Y\", \"INTERSECTION_NAME\",\"INT_KEY\",\"INTERSECTION_SUBAREA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a657df58",
   "metadata": {},
   "source": [
    "### Collector_Arterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15043826",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Collector_Arterial\n",
    "linear_regression(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ee593",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Collector_Arterial\n",
    "random_forest(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291d2ba",
   "metadata": {},
   "source": [
    "### Minor_Arterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f481fac2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Minor_Arterial\n",
    "linear_regression(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2fd63",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Minor_Arterial\n",
    "random_forest(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15be609",
   "metadata": {},
   "source": [
    "### Principal_Arterial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e3bd5",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Principal_Arterial\n",
    "linear_regression(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e55250",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Principal_Arterial\n",
    "random_forest(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdfd5e",
   "metadata": {},
   "source": [
    "### State_Highway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75773293",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = State_Highway\n",
    "linear_regression(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be939b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = State_Highway\n",
    "random_forest(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187af812",
   "metadata": {},
   "source": [
    "### Interstate_Freeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a263e0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = Interstate_Freeway\n",
    "linear_regression(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5cbb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Interstate_Freeway\n",
    "random_forest(data,\"COUNT_COLLISIONS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062777c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
